{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is a demo code where I have used T5 transformers to create an answer generation layer post retrieval but it didnt seem much effective in the local computer. I am noting down the methods and explanations of the functions being used in the code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully\n",
      "Initializing models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized successfully\n",
      "Processing query: How can I integrate ClearFeed with Jira?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Sources:\n",
      "1. https://docs.clearfeed.ai/clearfeed-help-center/integrations/jira-service-management (Score: 0.5828)\n",
      "2. https://docs.clearfeed.ai/clearfeed-help-center/integrations/jira (Score: 0.5694)\n",
      "3. https://docs.clearfeed.ai/clearfeed-help-center/answers/indexing-knowledge-sources/other-supported-ks (Score: 0.4308)\n",
      "4. https://docs.clearfeed.ai/clearfeed-help-center/getting-started/for-internal-support (Score: 0.4244)\n",
      "5. https://docs.clearfeed.ai/clearfeed-help-center/getting-started/using-clearfeed-with-microsoft-teams/installing-clearfeed-on-teams (Score: 0.4236)\n",
      "\n",
      "Generated Answer:\n",
      "Question: How can I integrate ClearFeed with Jira?\n",
      "    Context: Doc 1: jira service management page integrate atlassian enable ticketing functionalities sync settings tickets individual tickets message sync mode status sync mode helpful edit github https jira service man...\n",
      "Doc 2: jira page integrate atlassian enable ticketing emoji rules jira integration create tickets create tickets manually using emoji create tickets automatically functionalities sync settings tickets indivi...\n",
      "Doc 3: supported ks supported ks clearfeed also supports additional sources enrich knowledge base clearfeed enables integration partnering carbon ai learn https integrations disabled clearfeed account create...\n",
      "Doc 4: internal support internal support planning use clearfeed natively internal support follow guide clearfeed helpdesk planning use clearfeed internal support integration ticketing systems like zendesk ji...\n",
      "Doc 5: installing clearfeed teams installing clearfeed teams learn install clearfeed teams start monitoring conversations successfully authorized integrated clearfeed ms teams next step install clearfeed app...\n",
      "    Answer: Yes, the clearfeed app is integrated with Jira and the integration is enabled by default. This means that clearfeed is compatible with Jira, and is used by all users of Jira.\n",
      "Question: How can I integrate ClearFeed with Salesforce?\n",
      "    Context: Doc 1: salesforce service\n"
     ]
    }
   ],
   "source": [
    "#Demo Code\n",
    "import json\n",
    "import csv\n",
    "import nltk\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialize stop words globally\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "#Preprocessing text\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [t for t in tokens if t.isalnum() and t not in STOP_WORDS]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "#Loading data of the json file\n",
    "def load_data(csv_path, json_path):\n",
    "    try:\n",
    "        # Load CSV file\n",
    "        with open(csv_path, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            questions_answers = list(reader)\n",
    "        \n",
    "        # Load JSON knowledge base\n",
    "        with open(json_path, 'r') as f:\n",
    "            docs = json.load(f)\n",
    "        \n",
    "        # Process documents\n",
    "        documents = []\n",
    "        urls = []\n",
    "        for url, content in docs.items():\n",
    "            text = content['text']\n",
    "            title = content['title']\n",
    "            documents.append(preprocess_text(title + ' ' + text))\n",
    "            urls.append(url)\n",
    "        \n",
    "        return questions_answers, documents, urls\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find file - {e}\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Invalid JSON format - {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "#Models Initialisation\n",
    "def initialize_models():\n",
    "    try:\n",
    "        # Use smaller embedding model\n",
    "        retriever_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        \n",
    "        # Use smaller generation model\n",
    "        model_name = \"bigscience/bloom-560m\"  # Much smaller than Dolly\n",
    "        generator = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model_name,\n",
    "            device=-1  # Use CPU\n",
    "        )\n",
    "        \n",
    "        return retriever_model, generator\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing models: {e}\")\n",
    "        raise\n",
    "\n",
    "#Search Engine Function\n",
    "def retrieve(query, retriever_model, documents, urls, top_n=5):  \n",
    "    query_embedding = retriever_model.encode([query])\n",
    "    doc_embeddings = retriever_model.encode(documents)\n",
    "    \n",
    "    similarities = cosine_similarity(query_embedding, doc_embeddings).flatten()\n",
    "    top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        url = urls[idx]\n",
    "        score = similarities[idx]\n",
    "        doc_text = documents[idx][:1000]  # Limit text length\n",
    "        results.append({\n",
    "            'url': url,\n",
    "            'score': score,\n",
    "            'text': doc_text\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "#Post Retrieval Answer Generation\n",
    "def generate_answer(query, retrieved_docs, generator):\n",
    "    # Creating a shorter context\n",
    "    context = \"\\n\".join([\n",
    "        f\"Doc {i+1}: {doc['text'][:200]}...\"  # Limit context size\n",
    "        for i, doc in enumerate(retrieved_docs)\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"Question: {query}\n",
    "    Context: {context}\n",
    "    Answer:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = generator(\n",
    "            prompt,\n",
    "            max_length=250,  # Reduced length\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9\n",
    "        )\n",
    "        \n",
    "        return response[0]['generated_text']\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response: {str(e)}\"\n",
    "\n",
    "#Processing of the Query\n",
    "def process_query(query, retriever_model, generator, documents, urls):\n",
    "    print(f\"Processing query: {query}\\n\")\n",
    "    \n",
    "    try:\n",
    "        retrieved_docs = retrieve(query, retriever_model, documents, urls)\n",
    "        \n",
    "        print(\"Retrieved Sources:\")\n",
    "        for i, doc in enumerate(retrieved_docs, 1):\n",
    "            print(f\"{i}. {doc['url']} (Score: {doc['score']:.4f})\")\n",
    "        \n",
    "        answer = generate_answer(query, retrieved_docs, generator)\n",
    "        \n",
    "        print(\"\\nGenerated Answer:\")\n",
    "        print(answer)\n",
    "        \n",
    "        return {'retrieved_docs': retrieved_docs, 'answer': answer}\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing query: {e}\")\n",
    "        return None\n",
    "\n",
    "#Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"Loading data...\")\n",
    "        csv_path = 'clearfeed_qa_pairs.csv'\n",
    "        json_path = 'Clearfeed_kb.json'\n",
    "        \n",
    "        questions_answers, documents, urls = load_data(csv_path, json_path)\n",
    "        print(\"Data loaded successfully\")\n",
    "        \n",
    "        print(\"Initializing models...\")\n",
    "        retriever_model, generator = initialize_models()\n",
    "        print(\"Models initialized successfully\")\n",
    "        \n",
    "        query = \"How can I integrate ClearFeed with Jira?\"\n",
    "        result = process_query(query, retriever_model, generator, documents, urls)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error running the program: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, The use of Groq API Key and execution of the code under this method helped generate the accurate answer using the mistral open source model. Also, i went with gemini ai api key process but it was not giving me accurate results and some restrictions too were faced. The following code gives you the top results based on the confidence score and also provides a concrete answer that we can see in the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How can I integrate my Confluence account with ClearFeed?\n",
      "\n",
      "Top Sources:\n",
      "1. Confluence\n",
      "   URL: https://docs.clearfeed.ai/clearfeed-help-center/answers/indexing-knowledge-sources/confluence\n",
      "   Confidence: 0.8723\n",
      "\n",
      "2. Jira Service Management\n",
      "   URL: https://docs.clearfeed.ai/clearfeed-help-center/integrations/jira-service-management\n",
      "   Confidence: 0.6038\n",
      "\n",
      "3. Clickup\n",
      "   URL: https://docs.clearfeed.ai/clearfeed-help-center/integrations/clickup\n",
      "   Confidence: 0.5926\n",
      "\n",
      "4. Integrations\n",
      "   URL: https://docs.clearfeed.ai/clearfeed-help-center/pricing-and-billing/billing/integrations\n",
      "   Confidence: 0.5898\n",
      "\n",
      "5. Jira\n",
      "   URL: https://docs.clearfeed.ai/clearfeed-help-center/integrations/jira\n",
      "   Confidence: 0.5882\n",
      "\n",
      "Answer:\n",
      "To integrate your Confluence account with ClearFeed, follow these steps:\n",
      "\n",
      "1. Go to the ClearFeed web app and navigate to `Settings` from the nav-bar. Then, proceed to the `Integrations` tab.\n",
      "2. Within the list of available integrations, locate and select **Confluence**.\n",
      "3. Press the `Connect` button, which will bring up an input modal.\n",
      "4. Enter your Confluence subdomain in the first input field.\n",
      "5. Enter the email address of a Confluence administrator.\n",
      "6. Enter your Confluence email and API Key (use your PAT - personal access token).\n",
      "7. After entering these details, click the `Connect` button within the modal.\n",
      "\n",
      "Upon successful integration, you will be redirected back to ClearFeed's web app, and a confirmation message will be displayed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import nltk\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Initialize NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env\n",
    "\n",
    "\n",
    "class EnhancedQASystem:\n",
    "    def __init__(self, groq_api_key: str):\n",
    "        \"\"\"Initialize the QA system with Groq API access.\"\"\"\n",
    "        self.embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        self.groq_client = Groq(api_key=groq_api_key)\n",
    "        self.qa_pairs = []\n",
    "        self.qa_embeddings = None\n",
    "        self.docs_data = {}\n",
    "\n",
    "    def load_data(self, json_path: str, csv_path: str) -> None:\n",
    "        \"\"\"Load documentation and QA training data.\"\"\"\n",
    "        # Load JSON documentation\n",
    "        with open(json_path, 'r') as f:\n",
    "            self.docs_data = json.load(f)\n",
    "\n",
    "        # Load CSV QA pairs\n",
    "        with open(csv_path, 'r') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            self.qa_pairs = list(reader)\n",
    "\n",
    "        # Create embeddings for QA pairs\n",
    "        questions = [pair['question'] for pair in self.qa_pairs]\n",
    "        self.qa_embeddings = self.embedding_model.encode(questions)\n",
    "\n",
    "    def preprocess_text(self, text: str) -> List[str]:\n",
    "        \"\"\"Preprocess text by lowercasing, tokenizing, and removing stopwords.\"\"\"\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        tokens = [t for t in tokens if t.isalnum() and t not in STOP_WORDS]\n",
    "        return tokens\n",
    "\n",
    "    def calculate_word_overlap_score(self, query_tokens: List[str], doc_tokens: List[str]) -> float:\n",
    "        \"\"\"Calculate word overlap score between query and document.\"\"\"\n",
    "        query_counter = Counter(query_tokens)\n",
    "        doc_counter = Counter(doc_tokens)\n",
    "        overlap = sum((query_counter & doc_counter).values())\n",
    "        total = sum(query_counter.values())\n",
    "        return overlap / total if total > 0 else 0\n",
    "\n",
    "    def get_semantic_similarity(self, query: str, text: str) -> float:\n",
    "        \"\"\"Calculate semantic similarity using sentence embeddings.\"\"\"\n",
    "        embeddings = self.embedding_model.encode([query, text])\n",
    "        return cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "\n",
    "    def rank_documents(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Rank documents based on both word overlap and semantic similarity.\"\"\"\n",
    "        query_tokens = self.preprocess_text(query)\n",
    "        ranked_docs = []\n",
    "\n",
    "        for url, content in self.docs_data.items():\n",
    "            # Combine title and text for better matching\n",
    "            full_content = f\"{content['title']} {content['text']}\"\n",
    "            doc_tokens = self.preprocess_text(full_content)\n",
    "\n",
    "            # Calculate scores\n",
    "            word_overlap_score = self.calculate_word_overlap_score(query_tokens, doc_tokens)\n",
    "            semantic_score = self.get_semantic_similarity(query, full_content)\n",
    "\n",
    "            # Combine scores with adjusted weights\n",
    "            final_score = (0.3 * word_overlap_score) + (0.7 * semantic_score)\n",
    "\n",
    "            ranked_docs.append({\n",
    "                'url': url,\n",
    "                'title': content['title'],\n",
    "                'text': content['text'],\n",
    "                'score': final_score\n",
    "            })\n",
    "\n",
    "        ranked_docs.sort(key=lambda x: x['score'], reverse=True)\n",
    "        return ranked_docs[:top_k]\n",
    "\n",
    "    def prepare_context(self, ranked_docs: List[Dict[str, Any]], query: str) -> str:\n",
    "        \"\"\"Prepare context from top-ranked documents.\"\"\"\n",
    "        top_doc = ranked_docs[0]\n",
    "        context = f\"\"\"\n",
    "Document Title: {top_doc['title']}\n",
    "Content:\n",
    "{top_doc['text']}\n",
    "\"\"\"\n",
    "        prompt = f\"\"\"You are a knowledgeable assistant for ClearFeed. Based on the following document, answer the question:\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Document Context:\n",
    "{context}\n",
    "\n",
    "Instructions:\n",
    "1. Provide a clear and concise answer to the question based on the document context.\n",
    "2. If step-by-step instructions are relevant, number them clearly.\n",
    "3. Avoid introducing any content not found in the document.\n",
    "\n",
    "Answer:\"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def strip_markdown(self, text: str) -> str:\n",
    "        \"\"\"Remove Markdown formatting from text.\"\"\"\n",
    "        import re\n",
    "        # Remove headings (e.g., ## Heading)\n",
    "        text = re.sub(r'^#+\\s', '', text, flags=re.MULTILINE)\n",
    "        # Remove bullet points (e.g., -, *, etc.)\n",
    "        text = re.sub(r'^[-*]\\s', '', text, flags=re.MULTILINE)\n",
    "        return text.strip()\n",
    "\n",
    "    def generate_response(self, prompt: str) -> str:\n",
    "        \"\"\"Generate response using Groq API with enhanced formatting instructions.\"\"\"\n",
    "        try:\n",
    "            completion = self.groq_client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"\"\"You are a ClearFeed documentation expert. When responding:\n",
    "                        - Write answers in plain text only, without Markdown or special formatting\n",
    "                        - Use natural numbering for steps if needed, e.g., 1, 2, 3\n",
    "                        - Only include information found in the provided context\n",
    "                        - Clearly state if the information is missing\"\"\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ],\n",
    "                model=\"mixtral-8x7b-32768\",\n",
    "                temperature=0.4,\n",
    "                max_tokens=2048,\n",
    "                top_p=0.9\n",
    "            )\n",
    "            raw_response = completion.choices[0].message.content.strip()\n",
    "            return self.strip_markdown(raw_response)\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "\n",
    "    def process_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process a query and return an answer based on the top-ranked document.\"\"\"\n",
    "        ranked_docs = self.rank_documents(query, top_k=5)\n",
    "        if not ranked_docs:\n",
    "            return {\"answer\": \"No relevant documents found.\", \"sources\": []}\n",
    "\n",
    "        context = self.prepare_context(ranked_docs, query)\n",
    "        answer = self.generate_response(context)\n",
    "\n",
    "        return {\n",
    "            'answer': answer,\n",
    "            'sources': [\n",
    "                {'url': doc['url'], 'title': doc['title'], 'confidence': doc['score']}\n",
    "                for doc in ranked_docs\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "def main():\n",
    "    groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "    if not groq_api_key:\n",
    "        raise ValueError(\"Please set the GROQ_API_KEY environment variable\")\n",
    "    qa_system = EnhancedQASystem(groq_api_key)\n",
    "    qa_system.load_data('Clearfeed_kb.json', 'clearfeed_qa_pairs.csv')\n",
    "\n",
    "    query = \"How can I integrate my Confluence account with ClearFeed?\"\n",
    "    result = qa_system.process_query(query)\n",
    "\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"Top Sources:\")\n",
    "    for i, source in enumerate(result['sources'], 1):\n",
    "        print(f\"{i}. {source['title']}\")\n",
    "        print(f\"   URL: {source['url']}\")\n",
    "        print(f\"   Confidence: {source['confidence']:.4f}\\n\")\n",
    "\n",
    "    print(\"Answer:\")\n",
    "    print(result['answer'])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO, this was my whole thought process behind the code and I have also considered a lot of other methods which I am unable to include because it will take a whole lot of space. So, please consider this assignment completed and give me your thoughts on it. I have mentioned the requirements in the requirements.txt folder which you can go through. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
